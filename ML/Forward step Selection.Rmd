Forward Stepwise selection
==========================
Here we use the `regsubset` function with `method="forward"` option:
```{r}
library(ISLR)
library(leaps)
Hitters = na.omit(Hitters)
regfit.fwd = regsubsets(Salary~.,data=Hitters,nvmax = 19, method = "forward")
summary(regfit.fwd)
plot(regfit.fwd,scale="Cp")
```
Model Selection using a validation Set
======================================
```{r}
dim(Hitters)
set.seed(1)
train = sample(seq(263),180,replace = FALSE)
train
regfit.fwd = regsubsets(Salary~.,data=Hitters[train,],nvmax = 19, method = "forward")
```
Test on testset
```{r}
val.errors=rep(NA,20)
x.test = model.matrix(Salary~.,data=Hitters[-train,])
for(i in 1:19)
{
  coefi = coef(regfit.fwd,id=i)
  pred = x.test[,names(coefi)]%*%coefi
  val.errors[i] = mean((Hitters$Salary[-train]-pred)^2)
}
plot(sqrt(val.errors),ylab="Root MSE",ylim = c(300,400), pch=19, type="b")
# removing the NULL model
points(sqrt(regfit.fwd$rss[-1]/180),col="blue", pch=19, type="b")
legend("topright",legend = c("Training","Validation"),col=c("blue","black"),pch=19)
```

```{r}
predict.regsubsets = function(object,newdata,id,...)
{
  form = as.formula(object$call[[2]])
  mat = model.matrix(form,newdata)
  coefi = coef(object,id=id)
  mat[,names(coefi)]%*%coefi
}
```
Model Selection by Cross-Validation
===================================
```{r}
set.seed(11)
folds = sample(rep(1:10,length= nrow(Hitters)))
folds
table(folds)
cv.errors = matrix(NA,10,19)
for(k in 1:10)
{
  best.fit = regsubsets(Salary~.,data=Hitters[folds!=k,],nvmax = 19, method = "forward")
  for(i in 1:19)
  {
    pred = predict(best.fit,Hitters[folds==k,],id=i)
    cv.errors[k,i] = mean((Hitters$Salary[folds==k]-pred)^2)
  }
}
rmse.cv = sqrt(apply(cv.errors,2,mean))
plot(rmse.cv,pch=19,type="b")
```
Ridge Regression and Lasso
==========================
```{r}
library(glmnet)
x = model.matrix(Salary~.-1,data=Hitters)
y = Hitters$Salary
```
First we will fit a ridge regression model. This is acheived by calling `glmnet` with `alpha=0`
```{r}
fit.ridge = glmnet(x,y,alpha=0)
plot(fit.ridge,xvar="lambda", label=TRUE)
#default 10 fold cv
cv.ridge = cv.glmnet(x,y,alpha=0)
plot(cv.ridge)
```
Lasso model
```{r}
fit.lasso = glmnet(x,y)
plot(fit.lasso,xvar="lambda",label=TRUE)
cv.lasso = cv.glmnet(x,y)
plot(cv.lasso)
coef(cv.lasso)
```
Lasso from Cross validation
```{r}
lasso.tr = glmnet(x[train,],y[train])
lasso.tr
pred = predict(lasso.tr,x[-train,])
rmse = sqrt(apply((y[-train]-pred)^2,2,mean))
plot(log(lasso.tr$lambda),rmse,type="b",xlab="Log(lambda)")
lam.best = lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr,lam.best)
```
